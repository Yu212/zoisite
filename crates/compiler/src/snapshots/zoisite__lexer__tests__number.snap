---
source: crates/compiler/src/lexer.rs
expression: "tokenize(\"0 23 1.1\")"
---
(
    [
        Token {
            kind: Integer,
            text: "0",
            range: 0..1,
        },
        Token {
            kind: Whitespace,
            text: " ",
            range: 1..2,
        },
        Token {
            kind: Integer,
            text: "23",
            range: 2..4,
        },
        Token {
            kind: Whitespace,
            text: " ",
            range: 4..5,
        },
        Token {
            kind: Float,
            text: "1.1",
            range: 5..8,
        },
        Token {
            kind: Eof,
            text: "",
            range: 8..8,
        },
    ],
    [],
)
